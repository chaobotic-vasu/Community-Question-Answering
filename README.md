# Community-Question-Answering

## Domain:

CQA deals with generating relevant responses for community forums like Stack Overflow, Reddit, Quora like Lifestyle forums. Forums usually have Questions or Queries put on frequently by the users. These queries are subsequently answered by other community or users using the same web platform, thereby creating Answers or Comments. These responses are recorded and saved in a database that forms the knowledge base of the forum. The goal of CQA is essentially to harness this knowledge base, optimally and intelligently to devise an approach that automatically incurs valid responses to any new user.  As the user community expands on such forums, the automatic answering or retrieval of answers has become essential.

## Statement

In essence, CQA can be defined as "given (i) any question and (ii) a large collection of question-comment threads created by a user community identify the useful comment for answering the question”. Mathematically, this implies that for a Question Q with Answer set Ai (a0 to an), the best of n answers has to be shown to the user i.e., we are looking for as where 1 <= s <= n or a set of candidates as. Inherently, this means for any (Query, Response) pair, we have to classify whether the response is relevant/useful or irrelevant/useless to the query.
CQA occurs in three different phases: the answers must be (i) retrieved and classified, and (iii) ranked – in essence, this implies that answers are displayed to the user by their order of relevance. The present challenge is to automate just this process. In SemEval 2016, a similar CQA challenge was proposed and the dataset of Qatar Living Forum was released for the task. This dissertation chiefly focuses on the former phase i.e., identifying quality (or relevant) answers from the Qatar Living Forum data- formally known as, classification/selection of answers. We also perform experiments to examine and improve this classification of quality responses.

## Motivation

Even though a posed question is new with respect to the collection, it is expected to be related to one or several questions. So, an effective CQA system inspects the questions and its answers enabled with its features, language or data-dependent to find the best answers. Features like the nature of question posed, its topic, its title, its description, the website traffic, popularity can be used for selection of quality answers. These features have been described in detail in Chapter 2, and some of these have also been deployed in our work for finding quality of answers. With representation learning in NLP, the capability to exploit language features and similarity features between the Question’s text is also at our disposal. This clearly points towards a holistic way to traverse through knowledge base to provide answers. To experiment on this theory, SemEval proposed a challenge to rank answer in 2016 which encouraged to work with better word representations, a non-IR based approach and use NLP to handle answer ranking.
